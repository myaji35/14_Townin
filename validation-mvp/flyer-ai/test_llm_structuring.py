#!/usr/bin/env python3
"""
Test LLM Structuring Capability (without OCR)
Tests Claude's ability to structure Korean product data from raw text
"""

import os
import json
from pathlib import Path
from anthropic import Anthropic

# Mock OCR text samples (realistic Korean flyer text)
MOCK_OCR_SAMPLES = [
    {
        "name": "ÎßàÌä∏ Ï†ÑÎã®ÏßÄ - ÏãùÌíà",
        "ocr_text": """
        Ïù¥ÎßàÌä∏ Ï£ºÎßêÌäπÍ∞Ä!

        ÍπÄÏπòÏ∞åÍ∞úÏö© ÍπÄÏπò 9,900Ïõê 1+1
        Íµ≠ÎÇ¥ÏÇ∞ 100% ÌîÑÎ¶¨ÎØ∏ÏóÑ ÍπÄÏπò

        ÏÇºÍ≤πÏÇ¥ 1kg 12,900Ïõê
        Ïã†ÏÑ†Ìïú Íµ≠ÎÇ¥ÏÇ∞ ÎèºÏßÄÍ≥†Í∏∞

        ÏÇ¨Í≥º 5,900Ïõê/kg
        Ï≤≠ÏÜ° ÍøÄÏÇ¨Í≥º ÌäπÍ∞Ä

        Í≥ÑÎûÄ 30Íµ¨ 6,900Ïõê
        Î¨¥Ìï≠ÏÉùÏ†ú 1Îì±Í∏â
        """,
        "ground_truth": [
            {"product_name": "ÍπÄÏπòÏ∞åÍ∞úÏö© ÍπÄÏπò", "price": "9900", "unit": "Ïõê", "promotion": "1+1"},
            {"product_name": "ÏÇºÍ≤πÏÇ¥", "price": "12900", "unit": "Ïõê/kg", "promotion": None},
            {"product_name": "ÏÇ¨Í≥º", "price": "5900", "unit": "Ïõê/kg", "promotion": None},
            {"product_name": "Í≥ÑÎûÄ", "price": "6900", "unit": "Ïõê/30Íµ¨", "promotion": None}
        ]
    },
    {
        "name": "ÌôîÏû•Ìíà Ìï†Ïù∏",
        "ocr_text": """
        Ïò¨Î¶¨Î∏åÏòÅ ÎπÖÏÑ∏Ïùº!

        ÏÑ§ÌôîÏàò Ïú§Ï°∞ÏóêÏÑºÏä§ 129,000Ïõê
        (Ï†ïÏÉÅÍ∞Ä 258,000Ïõê)
        50% ÌäπÍ∞Ä!

        ÎùºÎÑ§Ï¶à ÏõåÌÑ∞Î±ÖÌÅ¨ ÏÑ∏Ìä∏ 29,900Ïõê
        ÌÜ†ÎÑà+ÏóêÎ©ÄÏ†Ñ+ÌÅ¨Î¶º 3Ï¢Ö

        Î©îÎîîÌûê ÎßàÏä§ÌÅ¨Ìå© 9,900Ïõê
        10Îß§ÏûÖ 2+1 ÌñâÏÇ¨
        """,
        "ground_truth": [
            {"product_name": "ÏÑ§ÌôîÏàò Ïú§Ï°∞ÏóêÏÑºÏä§", "price": "129000", "unit": "Ïõê", "original_price": "258000", "promotion": "50% Ìï†Ïù∏"},
            {"product_name": "ÎùºÎÑ§Ï¶à ÏõåÌÑ∞Î±ÖÌÅ¨ ÏÑ∏Ìä∏", "price": "29900", "unit": "Ïõê", "promotion": None},
            {"product_name": "Î©îÎîîÌûê ÎßàÏä§ÌÅ¨Ìå©", "price": "9900", "unit": "Ïõê/10Îß§", "promotion": "2+1"}
        ]
    },
    {
        "name": "ÏπòÌÇ® Ï†ÑÎã®ÏßÄ",
        "ocr_text": """
        BBQ ÏπòÌÇ® Ïù¥Î≤§Ìä∏!

        Ìô©Í∏àÏò¨Î¶¨Î∏å 18,000Ïõê
        Ïò§Î¶¨ÏßÄÎÑê + ÏΩúÎùº 1.25L Î¨¥Î£å

        Ìô©Í∏àÏò¨Î¶¨Î∏å + ÏñëÎÖêÏπòÌÇ® ÏΩ§Î≥¥ 32,000Ïõê
        (Í∞Å 1ÎßàÎ¶¨)

        ÏàúÏÇ¥ÏπòÌÇ® 19,000Ïõê
        Ìô©Í∏àÏò¨Î¶¨Î∏å/ÏñëÎÖê/Í∞ÑÏû• Ï§ë ÏÑ†ÌÉù

        12/31ÍπåÏßÄ
        """,
        "ground_truth": [
            {"product_name": "Ìô©Í∏àÏò¨Î¶¨Î∏å", "price": "18000", "unit": "Ïõê", "promotion": "ÏΩúÎùº 1.25L Î¨¥Î£å"},
            {"product_name": "Ìô©Í∏àÏò¨Î¶¨Î∏å + ÏñëÎÖêÏπòÌÇ® ÏΩ§Î≥¥", "price": "32000", "unit": "Ïõê", "promotion": None},
            {"product_name": "ÏàúÏÇ¥ÏπòÌÇ®", "price": "19000", "unit": "Ïõê", "promotion": None}
        ]
    },
    {
        "name": "Ï†ÑÏûêÏ†úÌíà Ìï†Ïù∏",
        "ocr_text": """
        ÌïòÏù¥ÎßàÌä∏ Ïó∞ÎßêÌäπÍ∞Ä

        ÏÇºÏÑ± Í∞§Îü≠Ïãú Î≤ÑÏ¶à2 ÌîÑÎ°ú 159,000Ïõê
        Ï†ïÏÉÅÍ∞Ä 229,000Ïõê ‚Üí 30% Ìï†Ïù∏

        LG Í∑∏Îû® ÎÖ∏Ìä∏Î∂Å 15Ïù∏Ïπò
        1,290,000Ïõê (Ïû¨Í≥†ÌïúÏ†ï)

        ÏóêÏñ¥Ìåü ÌîÑÎ°ú 2ÏÑ∏ÎåÄ
        298,000Ïõê
        Ïï†ÌîåÏºÄÏñ¥+ Ï∂îÍ∞ÄÏãú 349,000Ïõê
        """,
        "ground_truth": [
            {"product_name": "ÏÇºÏÑ± Í∞§Îü≠Ïãú Î≤ÑÏ¶à2 ÌîÑÎ°ú", "price": "159000", "unit": "Ïõê", "original_price": "229000", "promotion": "30% Ìï†Ïù∏"},
            {"product_name": "LG Í∑∏Îû® ÎÖ∏Ìä∏Î∂Å 15Ïù∏Ïπò", "price": "1290000", "unit": "Ïõê", "promotion": None},
            {"product_name": "ÏóêÏñ¥Ìåü ÌîÑÎ°ú 2ÏÑ∏ÎåÄ", "price": "298000", "unit": "Ïõê", "promotion": None}
        ]
    },
    {
        "name": "Ïπ¥Ìéò Î©îÎâ¥",
        "ocr_text": """
        Ïä§ÌÉÄÎ≤ÖÏä§ Ïã†Î©îÎâ¥

        ÏïÑÏù¥Ïä§ ÏïÑÎ©îÎ¶¨Ïπ¥ÎÖ∏ 4,500Ïõê

        Ïπ¥ÌéòÎùºÎñº (HOT/ICE) 5,000Ïõê

        ÌÅ¨Î¶¨Ïä§ÎßàÏä§ ÏºÄÏù¥ÌÅ¨ ÎùºÎñº 6,500Ïõê
        12Ïõî ÌïúÏ†ï ÏãúÏ¶å Î©îÎâ¥

        Ï¥àÏΩúÎ¶ø ÏºÄÏù¥ÌÅ¨ 5,800Ïõê
        ÏïÑÎ©îÎ¶¨Ïπ¥ÎÖ∏ÏôÄ ÏÑ∏Ìä∏ 9,000Ïõê
        """,
        "ground_truth": [
            {"product_name": "ÏïÑÏù¥Ïä§ ÏïÑÎ©îÎ¶¨Ïπ¥ÎÖ∏", "price": "4500", "unit": "Ïõê", "promotion": None},
            {"product_name": "Ïπ¥ÌéòÎùºÎñº", "price": "5000", "unit": "Ïõê", "promotion": None},
            {"product_name": "ÌÅ¨Î¶¨Ïä§ÎßàÏä§ ÏºÄÏù¥ÌÅ¨ ÎùºÎñº", "price": "6500", "unit": "Ïõê", "promotion": None},
            {"product_name": "Ï¥àÏΩúÎ¶ø ÏºÄÏù¥ÌÅ¨", "price": "5800", "unit": "Ïõê", "promotion": None},
            {"product_name": "ÏºÄÏù¥ÌÅ¨+ÏïÑÎ©îÎ¶¨Ïπ¥ÎÖ∏ ÏÑ∏Ìä∏", "price": "9000", "unit": "Ïõê", "promotion": None}
        ]
    }
]


class LLMStructuringTester:
    def __init__(self, api_key: str):
        self.client = Anthropic(api_key=api_key)
        self.total_cost = 0.0

    def structure_text(self, ocr_text: str) -> list:
        """Use Claude to structure OCR text into product JSON"""

        prompt = f"""You are a Korean retail product data extraction expert.

OCR Text from a Korean retail flyer:
{ocr_text}

Extract ALL products mentioned in this flyer and return a JSON array with the following structure:

[
  {{
    "product_name": "Ï†úÌíàÎ™Ö (Korean)",
    "price": "Í∞ÄÍ≤© (Ïà´ÏûêÎßå, Ïòà: 9900)",
    "unit": "Îã®ÏúÑ (Ïòà: Ïõê, Í∞ú, kg)",
    "original_price": "Ìï†Ïù∏ Ï†Ñ Í∞ÄÍ≤© (if applicable, else null)",
    "promotion": "ÌîÑÎ°úÎ™®ÏÖò (Ïòà: 1+1, 2+1, 50% Ìï†Ïù∏, null if none)",
    "description": "Í∞ÑÎã®Ìïú ÏÑ§Î™Ö (1-2 sentences)",
    "category": "Ïπ¥ÌÖåÍ≥†Î¶¨ (Ïòà: ÏãùÌíà, ÌôîÏû•Ìíà, Ï†ÑÏûêÏ†úÌíà)"
  }}
]

Rules:
1. Extract ONLY products with clear prices
2. If price is range (Ïòà: 5,000-10,000), use middle value
3. Understand Korean promotions: "1+1" (buy 1 get 1), "2+1", "Î∞òÍ∞í" (half price), "~% Ìï†Ïù∏" (discount)
4. If original_price not mentioned, set to null
5. Return valid JSON array ONLY (no markdown, no explanation)
"""

        try:
            message = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=2000,
                temperature=0,
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )

            # Calculate cost
            input_tokens = message.usage.input_tokens
            output_tokens = message.usage.output_tokens
            cost = (input_tokens / 1_000_000 * 3) + (output_tokens / 1_000_000 * 15)
            self.total_cost += cost

            # Parse response
            response_text = message.content[0].text.strip()

            # Remove markdown code blocks if present
            if response_text.startswith("```"):
                response_text = response_text.split("```")[1]
                if response_text.startswith("json"):
                    response_text = response_text[4:]
                response_text = response_text.strip()

            products = json.loads(response_text)

            return {
                "success": True,
                "products": products,
                "cost": cost,
                "tokens": {"input": input_tokens, "output": output_tokens}
            }

        except json.JSONDecodeError as e:
            return {
                "success": False,
                "error": f"JSON parsing failed: {e}",
                "raw_response": response_text[:500]
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def calculate_accuracy(self, extracted: list, ground_truth: list) -> dict:
        """Calculate extraction accuracy metrics"""

        if not ground_truth:
            return {"accuracy": 0, "message": "No ground truth"}

        # Match products by name (case-insensitive, partial match)
        extracted_names = {p.get("product_name", "").lower().strip() for p in extracted}
        truth_names = {p.get("product_name", "").lower().strip() for p in ground_truth}

        # Calculate matches
        correct = 0
        for truth_name in truth_names:
            for ext_name in extracted_names:
                # Allow partial matching (ÌïµÏã¨ ÌÇ§ÏõåÎìú Ìè¨Ìï®)
                if truth_name in ext_name or ext_name in truth_name:
                    correct += 1
                    break

        total = len(truth_names)
        precision = (correct / len(extracted)) * 100 if extracted else 0
        recall = (correct / total) * 100 if total > 0 else 0
        f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0

        return {
            "correct": correct,
            "total_ground_truth": total,
            "total_extracted": len(extracted),
            "precision": round(precision, 2),
            "recall": round(recall, 2),
            "f1_score": round(f1, 2)
        }


def main():
    print("=" * 70)
    print("Flyer AI - LLM Structuring Test (OCR ÏóÜÏù¥)")
    print("=" * 70)

    # Check API key
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("\n‚ùå ANTHROPIC_API_KEY not found in environment")
        print("   Please set it: export ANTHROPIC_API_KEY='your-key-here'")
        return

    tester = LLMStructuringTester(api_key)
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)

    all_results = []
    total_correct = 0
    total_ground_truth = 0
    total_extracted = 0

    # Test each sample
    for i, sample in enumerate(MOCK_OCR_SAMPLES, 1):
        print(f"\n{'='*70}")
        print(f"[{i}/{len(MOCK_OCR_SAMPLES)}] {sample['name']}")
        print(f"{'='*70}")
        print(f"\nOCR Text Preview:")
        print(sample['ocr_text'].strip()[:200] + "...")

        # Structure with LLM
        print(f"\n[Processing] Sending to Claude...")
        result = tester.structure_text(sample['ocr_text'])

        if result['success']:
            products = result['products']
            print(f"‚úì Extracted {len(products)} products")
            print(f"  Cost: ${result['cost']:.4f}")
            print(f"  Tokens: {result['tokens']['input']} in / {result['tokens']['output']} out")

            # Calculate accuracy
            accuracy = tester.calculate_accuracy(products, sample['ground_truth'])

            print(f"\n[Accuracy Metrics]")
            print(f"  Precision: {accuracy['precision']}%")
            print(f"  Recall: {accuracy['recall']}%")
            print(f"  F1 Score: {accuracy['f1_score']}%")
            print(f"  Matched: {accuracy['correct']}/{accuracy['total_ground_truth']}")

            # Show extracted products
            print(f"\n[Extracted Products]")
            for j, p in enumerate(products, 1):
                promo = f" ({p.get('promotion')})" if p.get('promotion') else ""
                print(f"  {j}. {p.get('product_name')} - {p.get('price')}Ïõê{promo}")

            all_results.append({
                "sample_name": sample['name'],
                "success": True,
                "products": products,
                "accuracy": accuracy,
                "cost": result['cost'],
                "tokens": result['tokens']
            })

            total_correct += accuracy['correct']
            total_ground_truth += accuracy['total_ground_truth']
            total_extracted += accuracy['total_extracted']

        else:
            print(f"‚úó Failed: {result['error']}")
            all_results.append({
                "sample_name": sample['name'],
                "success": False,
                "error": result['error']
            })

    # Final summary
    print("\n" + "=" * 70)
    print("VALIDATION SUMMARY")
    print("=" * 70)

    successful = [r for r in all_results if r['success']]

    print(f"\nTotal Samples: {len(MOCK_OCR_SAMPLES)}")
    print(f"Successful: {len(successful)}/{len(MOCK_OCR_SAMPLES)}")
    print(f"Total Cost: ${tester.total_cost:.4f}")
    print(f"Avg Cost per Sample: ${tester.total_cost / len(MOCK_OCR_SAMPLES):.4f}")

    if successful:
        avg_precision = sum(r['accuracy']['precision'] for r in successful) / len(successful)
        avg_recall = sum(r['accuracy']['recall'] for r in successful) / len(successful)
        avg_f1 = sum(r['accuracy']['f1_score'] for r in successful) / len(successful)

        print(f"\n[Overall Accuracy]")
        print(f"  Average Precision: {avg_precision:.2f}%")
        print(f"  Average Recall: {avg_recall:.2f}%")
        print(f"  Average F1 Score: {avg_f1:.2f}%")
        print(f"  Total Matched: {total_correct}/{total_ground_truth}")

        # Success criteria
        print(f"\n[Success Criteria Check]")
        if avg_f1 >= 90:
            print("  ‚úÖ EXCELLENT: F1 Score ‚â•90%")
        elif avg_f1 >= 85:
            print("  ‚úì GOOD: F1 Score ‚â•85%")
        elif avg_f1 >= 70:
            print("  ‚ö† ACCEPTABLE: F1 Score ‚â•70%")
        else:
            print("  ‚ùå NEEDS IMPROVEMENT: F1 Score <70%")

        if tester.total_cost / len(MOCK_OCR_SAMPLES) <= 0.05:
            print("  ‚úÖ COST: Excellent (‚â§$0.05/flyer)")
        elif tester.total_cost / len(MOCK_OCR_SAMPLES) <= 0.10:
            print("  ‚úì COST: Acceptable (‚â§$0.10/flyer)")
        else:
            print("  ‚ö† COST: Above target (>$0.10/flyer)")

    # Save results
    output_file = results_dir / "llm_structuring_results.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "total_samples": len(MOCK_OCR_SAMPLES),
            "successful": len(successful),
            "total_cost": round(tester.total_cost, 4),
            "avg_cost_per_sample": round(tester.total_cost / len(MOCK_OCR_SAMPLES), 4),
            "results": all_results
        }, f, ensure_ascii=False, indent=2)

    print(f"\nüìÑ Results saved to: {output_file}")
    print("=" * 70)


if __name__ == "__main__":
    main()
